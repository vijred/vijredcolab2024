{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16937d2a-d471-41ee-b43c-7f9cf32df9ba",
   "metadata": {},
   "source": [
    "## OpenAI Chat Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72ef1d-2fb9-499f-88b3-80d643793c0f",
   "metadata": {},
   "source": [
    "We need to install two librarys.\n",
    "\n",
    "**openai** is the library for working with the OpenAI API.   \n",
    "**python-dotenv** provides functions to read a .env file and assign environment variables.  We will use this to read the OpenAI API key without having it explicitly included in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3417d-4474-4381-99eb-966408fab502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519338eb-edfb-4fcc-b7a6-8bbe796a2c4c",
   "metadata": {},
   "source": [
    "Import opanai and dotenv libraries.   \n",
    "Load API key into environment from .env file which contains the line \"open_ai_key = [insert your API key here]\"   \n",
    "Instatiate client using OpenAI() function.\n",
    "\n",
    "**We will use the following code chunk repeatedly at the start of programs that use the openai library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50366388-fb9f-481e-abe0-fbe2e5c23dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openai_api_key\")\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73645f34-9ad4-4ac0-888d-c8905fc4353b",
   "metadata": {},
   "source": [
    "Define a function called **get_output**.    \n",
    "When called, this function will pass the prompt to OpenAI, along wtih other parameters (many optional) that we set.   \n",
    "The function will return the message content generated by the call to the OpenAI LLM as well as the total tokens used (prompt + completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0731e-f073-4a3d-bd70-63929856d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(prompt, model_input=\"gpt-3.5-turbo\", temperature_input = 0, top_p_input = 0) :\n",
    "    messages_from_prompt = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model = model_input,\n",
    "        messages = messages_from_prompt,\n",
    "        temperature = temperature_input,\n",
    "        top_p = top_p_input \n",
    "    )\n",
    "    response_content = response.choices[0].message.content\n",
    "    response_total_tokens = response.usage.total_tokens\n",
    "    return response_content, response_total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58daedc6-ac3f-48b5-9305-d6e1902e5e30",
   "metadata": {},
   "source": [
    "Create a prompt, asking for a list of 10 strategies for any task, project or initiative.  Be creative!   \n",
    "Call get_output function, with prompt and setting temperature equal to a number between 0 and 2.  Warning:  Setting a value of 2 can lead to errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a06097-7d99-4e20-b724-9215bb0a9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Propose 10 strategies to study for my final exams.   Create a list and describe each in just a few words.\n",
    "\"\"\"\n",
    "\n",
    "response, total_tokens = get_output(prompt, temperature_input = 1.5, top_p_input = 0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317060c8-3c34-46c7-9302-ab51167316dc",
   "metadata": {},
   "source": [
    "Print the total_tokens for the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb016a4-1838-4b3c-bbb9-292b1036ac6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3813fd72-a101-4432-ac6a-0799d80ce3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken\n",
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")  ## cl100k_base is the tokenizer for gpt-3.5-turbo and gpt-4, among other openai models\n",
    "##  tiktoken.encoding_for_model(\"gpt-3.5-turbo\")  you can find the tokenizer for a model using this code as well\n",
    "\n",
    "string = \"Propose 10 strategies to study for my final exams.   Create a list and describe each in just a few words.\"\n",
    "num_tokens = len(encoding.encode(string))\n",
    "num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e6ac8-2f49-4a8f-8284-03778b39d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.encode(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93786619-4f07-4d68-a58f-b64d9b854a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_bytes = [encoding.decode_single_token_bytes(token) for token in encoding.encode(string)]\n",
    "token_bytes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
