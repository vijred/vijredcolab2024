{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16937d2a-d471-41ee-b43c-7f9cf32df9ba",
   "metadata": {},
   "source": [
    "## First LLM application using OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72ef1d-2fb9-499f-88b3-80d643793c0f",
   "metadata": {},
   "source": [
    "We need to install two librarys.\n",
    "\n",
    "**openai** is the library for working with the OpenAI API.   \n",
    "**python-dotenv** provides functions to read a .env file and assign environment variables.  We will use this to read the OpenAI API key without having it explicitly included in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3417d-4474-4381-99eb-966408fab502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519338eb-edfb-4fcc-b7a6-8bbe796a2c4c",
   "metadata": {},
   "source": [
    "Import opanai and dotenv libraries.   \n",
    "Load API key into environment from .env file which contains the line \"open_ai_key = [insert your API key here]\"   \n",
    "Instatiate client using OpenAI() function.\n",
    "\n",
    "**We will use the following code chunk repeatedly at the start of programs that use the openai library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50366388-fb9f-481e-abe0-fbe2e5c23dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openai_api_key\")\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73645f34-9ad4-4ac0-888d-c8905fc4353b",
   "metadata": {},
   "source": [
    "Define a function called **get_output**.    \n",
    "When called, this function will pass the prompt to OpenAI, along wtih other parameters (many optional) that we set.  The function will return the completion generated by the call to the OpenAI LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0731e-f073-4a3d-bd70-63929856d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(prompt, model_input=\"gpt-3.5-turbo\", temperature_input = .5) :\n",
    "    messages_from_prompt = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model = model_input,\n",
    "        messages = messages_from_prompt,\n",
    "        temperature = temperature_input\n",
    "    )\n",
    "    response = response.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58daedc6-ac3f-48b5-9305-d6e1902e5e30",
   "metadata": {},
   "source": [
    "Create a prompt, using f-strings.\n",
    "Call get_output function, with prompt and setting temperature equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a06097-7d99-4e20-b724-9215bb0a9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "GBA 478 covers the application of generative AI technologies to a wide variety of business uses. The course \n",
    "will provide hands-on experience in designing, building and deploying generative AI tools to create value for \n",
    "business. It will guide you in knowing what is possible in integrating Generative AI into todayâ€™s business \n",
    "workflows, and provide frameworks to help decide how and when to utilize Generative AI. Last, the course \n",
    "will ask you to become conversant with the big questions about Generative AI, to debate the moral, \n",
    "philosophical, and ethical challenges inherent in this system.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Write a one sentence summary of the course description in the text {text}, to be used in a curriculum overview. \n",
    "\"\"\"\n",
    "\n",
    "response = get_output(prompt, temperature_input = 0)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
